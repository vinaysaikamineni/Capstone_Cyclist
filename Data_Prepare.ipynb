{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Cyclist Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extracting all the zip files to get the csv files [raw data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the directory where the zip files were stored and where you want to extract the files\n",
    "\n",
    "zip_directory = r\"C:\\Users\\daysi\\OneDrive\\Desktop\\Capstone_Cyclist\\Data_zip\"\n",
    "extract_directory = r\"C:\\Users\\daysi\\OneDrive\\Desktop\\Capstone_Cyclist\\Data_extract\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now extract all the zip files from the directory\n",
    "\n",
    "for filename in os.listdir(zip_directory):\n",
    "    if filename.endswith(\".zip\"):\n",
    "        with zipfile.ZipFile(os.path.join(zip_directory, filename), 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Now gathering the required data out of all the extracted files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a new directory only for the monthly trip data.\n",
    "# All the monthly data is of the format YEARMONTH-divy-tripdata.csv and YEARMONTH-divy-publictripdata.csv, so lets separate them from rest of the data.\n",
    "\n",
    "csv_files = glob.glob(os.path.join(extract_directory, '*-divvy-tripdata.csv')) + glob.glob(os.path.join(extract_directory, '*-divvy-publictripdata.csv'))\n",
    "\n",
    "# Create a list which contains all the csv files of each month trip data.\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for file in csv_files :\n",
    "    df = pd.read_csv(file)\n",
    "    df_list.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now combile all the files into single dataframe\n",
    "\n",
    "combined_df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets create a new csv file to store the gathered data.\n",
    "\n",
    "combined_df.to_csv(r\"C:\\Users\\daysi\\OneDrive\\Desktop\\Capstone_Cyclist\\Data_monthly.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. In the above block we got data from 04-2020 to 09-2024 now let's gather remaining data since 2013."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Year 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now in 2013 trip data folder we have one more zip file let's unzip it and check out the data.\n",
    "\n",
    "for filename in os.listdir(r\"C:\\Users\\daysi\\OneDrive\\Desktop\\Capstone_Cyclist\\Data_extract\\Divvy_Stations_Trips_2013\"):\n",
    "    if filename.endswith(\".zip\"):\n",
    "        with zipfile.ZipFile(os.path.join(r\"C:\\Users\\daysi\\OneDrive\\Desktop\\Capstone_Cyclist\\Data_extract\\Divvy_Stations_Trips_2013\", filename), 'r') as zip_ref:\n",
    "            zip_ref.extractall(r\"C:\\Users\\daysi\\OneDrive\\Desktop\\Capstone_Cyclist\\Data_extract\\Divvy_Stations_Trips_2013\")\n",
    "\n",
    "\n",
    "# We found no useful data in the extracted zip file.\n",
    "# we do have Divvy_Trips_2013.csv file which has 2013 trip data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Year 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it seems we have data from 3rd and 4th Quaters of year 2014 in a folder and Q1, Q2 as a xlsx sheet and csv file as well ouside the folder so let's add them to a single year file\n",
    "\n",
    "current_dir = r\"C:\\Users\\daysi\\OneDrive\\Desktop\\Capstone_Cyclist\\Data_extract\\Divvy_Stations_Trips_2014_Q3Q4\"\n",
    "another_dir = r\"C:\\Users\\daysi\\OneDrive\\Desktop\\Capstone_Cyclist\\Data_extract\"\n",
    "\n",
    "year_2014 = glob.glob(os.path.join(current_dir, 'Divvy_Trips_2014*.csv')) + glob.glob(os.path.join(another_dir, 'Divvy_Trips_2014*.csv'))\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for file in year_2014:\n",
    "    df = pd.read_csv(file)\n",
    "    df_list.append(df)\n",
    "\n",
    "\n",
    "year_2014_csv = pd.concat(df_list, ignore_index= True)\n",
    "\n",
    "year_2014_csv.to_csv(r\"C:\\Users\\daysi\\OneDrive\\Desktop\\Capstone_Cyclist\\Data_2014.csv\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Year 2015 to 2020 Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's append all the remaining data as well\n",
    "\n",
    "current_dir = r\"C:\\Users\\daysi\\OneDrive\\Desktop\\Capstone_Cyclist\\Data_extract\"\n",
    "\n",
    "remaining_Trip_data = glob.glob(os.path.join(current_dir, 'Divvy_Trips_*.csv'))\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for files in remaining_Trip_data:\n",
    "    df = pd.read_csv(files)\n",
    "    df_list.append(df)\n",
    "\n",
    "remain_data = pd.concat(df_list, ignore_index= True)\n",
    "\n",
    "remain_data.to_csv(r\"C:\\Users\\daysi\\OneDrive\\Desktop\\Capstone_Cyclist\\Data_extract\\remain_Data.csv\", index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Step to accumulate all the Trip data after arranging, sorting and filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Make sure that all the csv files have same headers before merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daysi\\AppData\\Local\\Temp\\ipykernel_13756\\151832285.py:3: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r\"Data_monthly.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>member_casual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A847FADBBC638E45</td>\n",
       "      <td>docked_bike</td>\n",
       "      <td>2020-04-26 17:45:14</td>\n",
       "      <td>2020-04-26 18:12:03</td>\n",
       "      <td>Eckhart Park</td>\n",
       "      <td>86</td>\n",
       "      <td>Lincoln Ave &amp; Diversey Pkwy</td>\n",
       "      <td>152.0</td>\n",
       "      <td>41.8964</td>\n",
       "      <td>-87.6610</td>\n",
       "      <td>41.9322</td>\n",
       "      <td>-87.6586</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5405B80E996FF60D</td>\n",
       "      <td>docked_bike</td>\n",
       "      <td>2020-04-17 17:08:54</td>\n",
       "      <td>2020-04-17 17:17:03</td>\n",
       "      <td>Drake Ave &amp; Fullerton Ave</td>\n",
       "      <td>503</td>\n",
       "      <td>Kosciuszko Park</td>\n",
       "      <td>499.0</td>\n",
       "      <td>41.9244</td>\n",
       "      <td>-87.7154</td>\n",
       "      <td>41.9306</td>\n",
       "      <td>-87.7238</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5DD24A79A4E006F4</td>\n",
       "      <td>docked_bike</td>\n",
       "      <td>2020-04-01 17:54:13</td>\n",
       "      <td>2020-04-01 18:08:36</td>\n",
       "      <td>McClurg Ct &amp; Erie St</td>\n",
       "      <td>142</td>\n",
       "      <td>Indiana Ave &amp; Roosevelt Rd</td>\n",
       "      <td>255.0</td>\n",
       "      <td>41.8945</td>\n",
       "      <td>-87.6179</td>\n",
       "      <td>41.8679</td>\n",
       "      <td>-87.6230</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2A59BBDF5CDBA725</td>\n",
       "      <td>docked_bike</td>\n",
       "      <td>2020-04-07 12:50:19</td>\n",
       "      <td>2020-04-07 13:02:31</td>\n",
       "      <td>California Ave &amp; Division St</td>\n",
       "      <td>216</td>\n",
       "      <td>Wood St &amp; Augusta Blvd</td>\n",
       "      <td>657.0</td>\n",
       "      <td>41.9030</td>\n",
       "      <td>-87.6975</td>\n",
       "      <td>41.8992</td>\n",
       "      <td>-87.6722</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27AD306C119C6158</td>\n",
       "      <td>docked_bike</td>\n",
       "      <td>2020-04-18 10:22:59</td>\n",
       "      <td>2020-04-18 11:15:54</td>\n",
       "      <td>Rush St &amp; Hubbard St</td>\n",
       "      <td>125</td>\n",
       "      <td>Sheridan Rd &amp; Lawrence Ave</td>\n",
       "      <td>323.0</td>\n",
       "      <td>41.8902</td>\n",
       "      <td>-87.6262</td>\n",
       "      <td>41.9695</td>\n",
       "      <td>-87.6547</td>\n",
       "      <td>casual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ride_id rideable_type           started_at             ended_at  \\\n",
       "0  A847FADBBC638E45   docked_bike  2020-04-26 17:45:14  2020-04-26 18:12:03   \n",
       "1  5405B80E996FF60D   docked_bike  2020-04-17 17:08:54  2020-04-17 17:17:03   \n",
       "2  5DD24A79A4E006F4   docked_bike  2020-04-01 17:54:13  2020-04-01 18:08:36   \n",
       "3  2A59BBDF5CDBA725   docked_bike  2020-04-07 12:50:19  2020-04-07 13:02:31   \n",
       "4  27AD306C119C6158   docked_bike  2020-04-18 10:22:59  2020-04-18 11:15:54   \n",
       "\n",
       "             start_station_name start_station_id             end_station_name  \\\n",
       "0                  Eckhart Park               86  Lincoln Ave & Diversey Pkwy   \n",
       "1     Drake Ave & Fullerton Ave              503              Kosciuszko Park   \n",
       "2          McClurg Ct & Erie St              142   Indiana Ave & Roosevelt Rd   \n",
       "3  California Ave & Division St              216       Wood St & Augusta Blvd   \n",
       "4          Rush St & Hubbard St              125   Sheridan Rd & Lawrence Ave   \n",
       "\n",
       "  end_station_id  start_lat  start_lng  end_lat  end_lng member_casual  \n",
       "0          152.0    41.8964   -87.6610  41.9322 -87.6586        member  \n",
       "1          499.0    41.9244   -87.7154  41.9306 -87.7238        member  \n",
       "2          255.0    41.8945   -87.6179  41.8679 -87.6230        member  \n",
       "3          657.0    41.9030   -87.6975  41.8992 -87.6722        member  \n",
       "4          323.0    41.8902   -87.6262  41.9695 -87.6547        casual  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see if all the files were are going to merge have headers\n",
    "\n",
    "df = pd.read_csv(r\"Data_monthly.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ride_id', 'rideable_type', 'started_at', 'ended_at',\n",
      "       'start_station_name', 'start_station_id', 'end_station_name',\n",
      "       'end_station_id', 'start_lat', 'start_lng', 'end_lat', 'end_lng',\n",
      "       'member_casual'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>from_station_id</th>\n",
       "      <th>from_station_name</th>\n",
       "      <th>to_station_id</th>\n",
       "      <th>to_station_name</th>\n",
       "      <th>usertype</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2886259</td>\n",
       "      <td>7/31/2014 23:56</td>\n",
       "      <td>8/1/2014 0:03</td>\n",
       "      <td>2602</td>\n",
       "      <td>386</td>\n",
       "      <td>291</td>\n",
       "      <td>Wells St &amp; Evergreen Ave</td>\n",
       "      <td>53</td>\n",
       "      <td>Wells St &amp; Erie St</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Female</td>\n",
       "      <td>1979.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2886258</td>\n",
       "      <td>7/31/2014 23:58</td>\n",
       "      <td>8/1/2014 0:07</td>\n",
       "      <td>2403</td>\n",
       "      <td>495</td>\n",
       "      <td>98</td>\n",
       "      <td>LaSalle St &amp; Washington St</td>\n",
       "      <td>106</td>\n",
       "      <td>State St &amp; Pearson St</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1974.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2886257</td>\n",
       "      <td>7/31/2014 23:58</td>\n",
       "      <td>8/1/2014 2:10</td>\n",
       "      <td>669</td>\n",
       "      <td>7947</td>\n",
       "      <td>240</td>\n",
       "      <td>Sheridan Rd &amp; Irving Park Rd</td>\n",
       "      <td>240</td>\n",
       "      <td>Sheridan Rd &amp; Irving Park Rd</td>\n",
       "      <td>Customer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2886256</td>\n",
       "      <td>7/31/2014 23:58</td>\n",
       "      <td>8/1/2014 0:19</td>\n",
       "      <td>2431</td>\n",
       "      <td>1282</td>\n",
       "      <td>47</td>\n",
       "      <td>State St &amp; Kinzie St</td>\n",
       "      <td>14</td>\n",
       "      <td>Morgan St &amp; 18th St</td>\n",
       "      <td>Customer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2886255</td>\n",
       "      <td>7/31/2014 23:57</td>\n",
       "      <td>8/1/2014 2:10</td>\n",
       "      <td>2885</td>\n",
       "      <td>7972</td>\n",
       "      <td>240</td>\n",
       "      <td>Sheridan Rd &amp; Irving Park Rd</td>\n",
       "      <td>240</td>\n",
       "      <td>Sheridan Rd &amp; Irving Park Rd</td>\n",
       "      <td>Customer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trip_id        starttime       stoptime  bikeid  tripduration  \\\n",
       "0  2886259  7/31/2014 23:56  8/1/2014 0:03    2602           386   \n",
       "1  2886258  7/31/2014 23:58  8/1/2014 0:07    2403           495   \n",
       "2  2886257  7/31/2014 23:58  8/1/2014 2:10     669          7947   \n",
       "3  2886256  7/31/2014 23:58  8/1/2014 0:19    2431          1282   \n",
       "4  2886255  7/31/2014 23:57  8/1/2014 2:10    2885          7972   \n",
       "\n",
       "   from_station_id             from_station_name  to_station_id  \\\n",
       "0              291      Wells St & Evergreen Ave             53   \n",
       "1               98    LaSalle St & Washington St            106   \n",
       "2              240  Sheridan Rd & Irving Park Rd            240   \n",
       "3               47          State St & Kinzie St             14   \n",
       "4              240  Sheridan Rd & Irving Park Rd            240   \n",
       "\n",
       "                to_station_name    usertype  gender  birthyear  \n",
       "0            Wells St & Erie St  Subscriber  Female     1979.0  \n",
       "1         State St & Pearson St  Subscriber    Male     1974.0  \n",
       "2  Sheridan Rd & Irving Park Rd    Customer     NaN        NaN  \n",
       "3           Morgan St & 18th St    Customer     NaN        NaN  \n",
       "4  Sheridan Rd & Irving Park Rd    Customer     NaN        NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"Data_2014.csv\", nrows= 1000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example format for dates, adjust according to your actual format\n",
    "df['started_at'] = pd.to_datetime(df['started_at'], format='%Y-%m-%d %H:%M:%S.%f', errors='coerce')\n",
    "\n",
    "# Example format for dates, adjust according to your actual format\n",
    "df['ended_at'] = pd.to_datetime(df['ended_at'], format='%Y-%m-%d %H:%M:%S.%f', errors='coerce')\n",
    "\n",
    "\n",
    "starting = df['started_at'].min()\n",
    "ending = df['started_at'].max()\n",
    "type(df['started_at'])\n",
    "#print(starting,ending, sep = \"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's gather last 12 months of data\n",
    "\n",
    "# Calculate the date 12 months ago\n",
    "last_12_months_date = df['started_at'].max() - pd.DateOffset(months=12)\n",
    "\n",
    "# Filter the DataFrame for the last 12 months\n",
    "df_last_12_months = df[df['started_at'] >= last_12_months_date]\n",
    "\n",
    "# LET'S GET THIS DATA INTO A NEW FILE WHICH WE CONSIDER AS OUR DATASET FOR FUTURE ANALYSIS\n",
    "\n",
    "dataset = df_last_12_months.to_csv(r\"C:\\Users\\daysi\\OneDrive\\Desktop\\Capstone_Cyclist\\Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>from_station_id</th>\n",
       "      <th>from_station_name</th>\n",
       "      <th>to_station_id</th>\n",
       "      <th>to_station_name</th>\n",
       "      <th>usertype</th>\n",
       "      <th>...</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>member_casual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2355134.0</td>\n",
       "      <td>6/30/2014 23:57</td>\n",
       "      <td>7/1/2014 0:07</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>604</td>\n",
       "      <td>131.0</td>\n",
       "      <td>Lincoln Ave &amp; Belmont Ave</td>\n",
       "      <td>303.0</td>\n",
       "      <td>Broadway &amp; Cornelia Ave</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2355133.0</td>\n",
       "      <td>6/30/2014 23:56</td>\n",
       "      <td>7/1/2014 0:00</td>\n",
       "      <td>2217.0</td>\n",
       "      <td>263</td>\n",
       "      <td>282.0</td>\n",
       "      <td>Halsted St &amp; Maxwell St</td>\n",
       "      <td>22.0</td>\n",
       "      <td>May St &amp; Taylor St</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2355130.0</td>\n",
       "      <td>6/30/2014 23:33</td>\n",
       "      <td>6/30/2014 23:35</td>\n",
       "      <td>2798.0</td>\n",
       "      <td>126</td>\n",
       "      <td>327.0</td>\n",
       "      <td>Sheffield Ave &amp; Webster Ave</td>\n",
       "      <td>225.0</td>\n",
       "      <td>Halsted St &amp; Dickens Ave</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2355129.0</td>\n",
       "      <td>6/30/2014 23:26</td>\n",
       "      <td>7/1/2014 0:24</td>\n",
       "      <td>173.0</td>\n",
       "      <td>3481</td>\n",
       "      <td>134.0</td>\n",
       "      <td>Peoria St &amp; Jackson Blvd</td>\n",
       "      <td>194.0</td>\n",
       "      <td>State St &amp; Wacker Dr</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2355128.0</td>\n",
       "      <td>6/30/2014 23:16</td>\n",
       "      <td>6/30/2014 23:26</td>\n",
       "      <td>173.0</td>\n",
       "      <td>638</td>\n",
       "      <td>320.0</td>\n",
       "      <td>Loomis St &amp; Lexington St</td>\n",
       "      <td>134.0</td>\n",
       "      <td>Peoria St &amp; Jackson Blvd</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     trip_id        starttime         stoptime  bikeid  tripduration  \\\n",
       "0  2355134.0  6/30/2014 23:57    7/1/2014 0:07  2006.0           604   \n",
       "1  2355133.0  6/30/2014 23:56    7/1/2014 0:00  2217.0           263   \n",
       "2  2355130.0  6/30/2014 23:33  6/30/2014 23:35  2798.0           126   \n",
       "3  2355129.0  6/30/2014 23:26    7/1/2014 0:24   173.0          3481   \n",
       "4  2355128.0  6/30/2014 23:16  6/30/2014 23:26   173.0           638   \n",
       "\n",
       "   from_station_id            from_station_name  to_station_id  \\\n",
       "0            131.0    Lincoln Ave & Belmont Ave          303.0   \n",
       "1            282.0      Halsted St & Maxwell St           22.0   \n",
       "2            327.0  Sheffield Ave & Webster Ave          225.0   \n",
       "3            134.0     Peoria St & Jackson Blvd          194.0   \n",
       "4            320.0     Loomis St & Lexington St          134.0   \n",
       "\n",
       "            to_station_name    usertype  ... ended_at  start_station_name  \\\n",
       "0   Broadway & Cornelia Ave  Subscriber  ...      NaN                 NaN   \n",
       "1        May St & Taylor St  Subscriber  ...      NaN                 NaN   \n",
       "2  Halsted St & Dickens Ave  Subscriber  ...      NaN                 NaN   \n",
       "3      State St & Wacker Dr  Subscriber  ...      NaN                 NaN   \n",
       "4  Peoria St & Jackson Blvd  Subscriber  ...      NaN                 NaN   \n",
       "\n",
       "   start_station_id  end_station_name  end_station_id  start_lat  start_lng  \\\n",
       "0               NaN               NaN             NaN        NaN        NaN   \n",
       "1               NaN               NaN             NaN        NaN        NaN   \n",
       "2               NaN               NaN             NaN        NaN        NaN   \n",
       "3               NaN               NaN             NaN        NaN        NaN   \n",
       "4               NaN               NaN             NaN        NaN        NaN   \n",
       "\n",
       "   end_lat  end_lng  member_casual  \n",
       "0      NaN      NaN            NaN  \n",
       "1      NaN      NaN            NaN  \n",
       "2      NaN      NaN            NaN  \n",
       "3      NaN      NaN            NaN  \n",
       "4      NaN      NaN            NaN  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"remain_Data.csv\", nrows= 1000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = r\"C:\\Users\\daysi\\OneDrive\\Desktop\\Capstone_Cyclist\"\n",
    "\n",
    "final_data = glob.glob(os.path.join(current_dir, '*.csv'))\n",
    "\n",
    "dtype_spec = {\n",
    "    'start_station_name': 'str',  \n",
    "    'end_station_name': 'str' \n",
    "}\n",
    "\n",
    "chunk_size = 1000000\n",
    "\n",
    "df_list = []\n",
    "for files in final_data:\n",
    "    for chunk in pd.read_csv(files, chunksize=chunk_size, dtype=dtype_spec, low_memory=False):\n",
    "        df_list.append(chunk)\n",
    "\n",
    "final_data_combined = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "final_data_combined.to_csv(r\"C:\\Users\\daysi\\OneDrive\\Desktop\\Capstone_Cyclist\\Data_Final.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
